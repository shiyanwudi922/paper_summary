《Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition》

摘要：

1、传统的CNN要求输入的图像大小是固定的 ==> 尺寸固定的要求是“人工”要求的（实际上来源于全连接层的要求，因为卷积层可以对任意大小的图像进行处理，而全连接层只能处理固定长度的向量） ==> 当输入图像是任意大小时，需要进行转换，从而降低了识别/分类的准确率；

2、引入了SPP的pooling层结构：

（1）通过使pooling层滑动窗口的尺寸可变，从而对于任意尺寸的输入都可以产生固定长度的输出，从而使得输入不再需要进行变换，减少了失真；

（2）在pooling层使用多个固定输出尺寸的窗口（1x1，2x2，4x4……），从多个尺度来提取特征，增强网络的表示能力，同时对目标的形变具有鲁棒性

（3）在分类时，可以直接输入整个图像，而不用使用多视角测试，一方面可以充分使用全图的背景和边缘信息，另一方面CNN不用传输多次，提高了计算速度

（4）在实体检测时，不需要对每一个region都先warp再进行一次CNN传输来提取固定大小的特征向量，而是通过先对全图进行一次CNN传输得到全图的feature map，然后把原图中的region映射到feature map中的region，再对feature map中的region分别进行spp，从而对每一个region都得到了固定大小的向量。优点：1、不需要warp，减少了失真；2、使用全图的feature map，充分使用了全图的信息；3、只需要进行一次CNN传输，极大地提高了速度。

一、介绍：

1、流行的CNN要求输入图像的尺寸是固定的，从而带来一些问题：

（1）使用crop：会导致信息丢失

（2）使用warp：会导致失真

（3）固定尺寸的输入忽略了实体的比例

2、固定输入尺寸的原因：完全来源于全连接层。而卷积层以滑动窗口的形式进行操作，可以接受任意大小的输入。

3、在最后一个卷积层和之后的全连接层之间加入SPP层，相当于在网络层次的较深阶段进行了一些信息聚合，从而输出固定长度的特征，避免了crop和warp。SPPnet的工作方式：

![image](https://github.com/shiyanwudi922/paper_summary/blob/master/picture/SPPnet/figure%203.png)

4、SPP层对图像进行不同粒度的分割，再对局部特征进行聚合。对CNN来说具有特殊的性质：

（1）可以接受任意大小的输入

（2）可以产生固定大小的输出

（3）具有多个尺寸的窗口

5、SPP层允许在训练时使用不同尺寸的输入:

（1）提升了伸缩不变性，并且减小了过拟合

（2）理解：单个网络接受不同尺寸的输入，相当于多个只接受固定尺寸输入的网络共享其参数。

（3）训练方式：在每一个epoch，使用一种不同尺寸的数据进行训练。

6、SPP层的优点和具体的CNN的设计无关，所以理论上可以对任意的CNN进行改进。

7、将SPP用于实体检测时，通过对全图进行CNN传输，然后在feature map上的对应区域进行特征提取，优点：

（1）、不需要warp和crop，减少了失真；

（2）、使用全图的feature map，充分使用了全图的信息；

（3）、对于所有region的检测，只需要进行一次CNN传输，极大地提高了速度。

二、使用SPP的深度网络

1、原始的pooling窗口的大小不变，对于不同尺寸的输入，会产生不同尺寸的输出；

SPP窗口的大小会随输入的尺寸按比例地变化，从而保证对于不同尺寸的输入，会产生相同尺寸的输出。

2、在深度网络中使用SPP时，会把最后一个pooling层替换成SPP层。

3、SPP的使用使得输入可以是任意尺寸（size）：

（1）任意的纵横比（aspect ratio）

（2）任意的尺度（scale）

a、可以对输入进行resize到任意的尺度，而使用相同的网络

b、对于不同尺度的输入，会在不同的尺度上提取特征

c、尺度对于深度网络的准确率具有重要的影响

4、SPP层中最大的窗口和输入的feature map同样大，称作“global pooling”，与传统方法中的bag-of-words相对应。

5、单尺寸训练

（1）数据：从原图像中切取的固定大小的子图，这里使用crop的意义在于数据增强（data augmentation）

（2）网络结构：由于是单尺寸训练，所以可以预先计算SPP层的窗口和步长，在训练过程中不再改变

（3）单尺寸训练的目的是使多级别的pooling生效（即多个窗口尺寸的pooling），从而从多个尺度提取特征，提高准确率

6、多尺寸训练

（1）数据：对已有的224*224的数据进行resize，从而保证不同size的数据集之间的不同点只有分辨率，而内容都相同

（2）网络：对于不同的输入size，计算对应的SPP层窗口和步长的大小，使得不同输入size的网络结构只有在SPP层上有所不同，其余结构都相同。一方面可以做到不同的输入size都有相同size的输出，另一方面可以做到不同输入size的网络之间可以进行参数共享

（3）训练：在每一个epoch，使用给size的输入，而不同的epoch，输入的size不同

（4）目的：对真实情况中的不同size的输入进行模拟

（5）注意：在测试时，对每一个输入图像，都要修改SPP层的配置，从而使网络可以应用到任意大小的输入。

三、SPPnet用于图像分类

1、多级别的pooling会提升准确率

（1）从多个尺度来提取特征

（2）参数更多（SPP层和之后的全连接层之间的连接数更多）

（3）多级别的pooling对于目标的形变具有更好的鲁棒性

2、使用多尺寸的训练集进行训练会提升准确率，但是，是否使用的尺寸越多越好，仍需要验证

3、对整个图像进行特征提取，而不是对其中某个视角的子图来提取特征，会提高准确率：保留了整个图像的特征。

（1）准确率：一个视角的特征<整个图像的特征<多个视角的特征的结合

（2）对全图进行特征表示的优点：

a、即使已经结合了多个视角的特征，使用全图的特征仍然可以把准确率提升0.2%

b、对全图进行特征表示的方法和传统方法具有一致性

c、在分类以外的其他应用中，全图的特征更加有用

4、feature map上的多视角测试：

（1）测试方案中变化因子：

a、原始图像缩放成多少个尺寸

b、使用多少个视角（view/window）

c、每个视角单独进行CNN+SPP特征提取；还是整个图像先进行CNN提取feature map，再将每个view映射到feature map上，最后对每个view进行SPP提取特征

（2）最优的方案是使用多尺寸、多视角，feature map特征映射进行测试。

四、SPPnet用于实体检测

1、把整个图像通过CNN传输得到feature map，在将原图上的region映射到feature map上，对feature map上的每一个region进行SPP。即只通过一次CNN传输就得到了所有的region的特征，且不需要固定region的大小

2、提取特征时方法：

（1）在提取出proposal之后，对整个图像提取特征之前，会先对整个图像进行resize，使得min(w,h) = s, 而 s 的取值范围是S={480， 576， 688， 864，1200}

（2）对于每一个proposal，把它分配到某一个s取值的resize后的图像上，这里s要满足的条件是使得该proposal在该图像上的对应尺寸尽量接近224*224

（3）分配完之后，将每一个s取值的图像进行CNN传输得到feature map，并使用SPP对其中的region进行特征提取，如下图：

![image](https://github.com/shiyanwudi922/paper_summary/blob/master/picture/SPPnet/figure%205.png)

（4）所有的s取值的图像对应的feature map上的region的特征集合即为原图像中所有proposal对应的特征集合

3、微调时，由于SPP层会变化，所有只对全连接层进行微调

4、复杂度和运行时间分析与对比：

（1）、R-CNN中的做法：每一个region proposal都要进行一次CNN传输；

SPPnet的做法：所有的region proposal只要进行一次CNN传输（单个scale的情况）；

所有的region proposal进行预定义次数的CNN传输（多个scale的情况）。

CNN传输的次数大幅度下降，所以SPPnet的速度提高了两个数量级，同时其检测准确率并没有下降。

（2）、当把proposal计算的方法替换成更有效的方法后，整体的检测速度会更快（selective search换成edgebox）。

5、多模型结合用于实体检测：

（1）、训练一个相同结构、不同初始化的网络；用两个网络同时对region proposal打分，再进行non-maximum suppression；最终的结果会有进一步提升；

（2）、说明这两个网络是互补的，这种互补性主要来源于卷积层。

五、附件

1、将原图像中的窗口映射到feature map中的窗口 => 原图像中的点映射到feature map中的点：

（1）方法：已知原图像中的点(x,y)，对于feature map中的所有的点，计算它们在原图像中的receptive field的中心点，若feature map中的点(x', y')对应的receptive field的中心点离(x,y)的距离最近，则将（x，y）映射到（x', y'）

（2）简化（因为padding会使问题变得更复杂）：对于每一个卷积层或pooling层，如果其filter size为p，则padding为p/2。那么，原图中的点（x，y）和其对应的feature map中的点（x'，y'）之间的关系为：

（x，y） = （S*x', S*y'）

以及

（左/上点）：（x'，y'） = （ floor(x/S) + 1, floor(y/S) + 1 ）

（右/下点）：（x'，y'） = （ ceil(x/S) - 1, ceil(y/S) - 1 ）

其中，S为feature map层之前所有的步长的乘积。