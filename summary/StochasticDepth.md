一、摘要

1、层数非常多的网络通常具有很多问题，例如：gradient vanish、forward flow diminish、训练时间非常长等。

2、本文中提出一种stochastic depth的训练方法，使用了一种看似矛盾的配置：在训练时使用比较浅的网络，但是在测试时使用深层网络

3、做法是：从非常深的网络开示，在训练中，对于每一个mini-batch，随机地丢弃一些网络层，用恒等变换来代替。

